{"cells":[{"cell_type":"markdown","metadata":{"id":"1FINXtI_RPDZ"},"source":["# 1. Download dipendenze"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"jK38Bw2iOXtl","executionInfo":{"status":"ok","timestamp":1737736025924,"user_tz":-60,"elapsed":220,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["# !pip install torchtext==0.17.0\n","# !pip install spacy\n","\n","# # installing spacy italian language\n","# !python -m spacy download it_core_news_sm"]},{"cell_type":"markdown","metadata":{"id":"pBkMIvB2R6sJ"},"source":["# 2. Import"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"CnE0cr0VLx9s","executionInfo":{"status":"ok","timestamp":1737736025925,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import pandas as pd\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","import torchtext.transforms as T\n","from torch.utils.data import Dataset\n","from torch import Tensor\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import numpy as np\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JMxcvRf1N5OV"},"source":["# 3. Custom Dataset"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":923,"status":"ok","timestamp":1737736026845,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"},"user_tz":-60},"id":"mdpzS8TzN8Xh","outputId":"ed7d81de-e9ac-4e1f-e891-21dff19677b7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]},{"output_type":"stream","name":"stdout","text":["---------------------------------\n","Dataset Info\n","---------------------------------\n","Data location:\t\"datasets/train/train.csv\"\n","Data length:\t1000 records\n","Source vocab length:\t208 words\n","Target vocab length:\t1253 words\n","---------------------------------\n","END Info\n","---------------------------------\n","Campione 0: {'input_ids': tensor([ 2,  5, 14, 19,  9, 84,  8,  4, 91,  7, 33, 13, 12, 17, 11,  3,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1]), 'labels': tensor([  2,   8,   5,  14,  18,   6,  10,   5,   7,   4,  12,   4, 287,   6,\n","          9,   5,   7,   4,  12,   4, 289,   3,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1])}\n","Campione 1: {'input_ids': tensor([ 2,  5, 28,  9, 84,  8,  4, 36,  7, 31, 13, 12, 27, 11,  3,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1]), 'labels': tensor([  2,   8,   5,  24,   6,  10,   5,   7,   4,  12,   4, 101,   6,   9,\n","          5,   7,   4,  12,   4, 685,   3,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1])}\n","Campione 2: {'input_ids': tensor([ 2,  5, 15, 25,  9, 30,  8,  4, 58,  7, 33, 13, 12, 18, 11,  3,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1]), 'labels': tensor([  2,   8,   5,  15,  22,   6,  10,   5,   7,   4,  17,   4, 508,   6,\n","          9,   5,   7,   4,  17,   4, 510,   3,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1])}\n","Campione 3: {'input_ids': tensor([ 2,  5, 16, 23,  9, 30,  8,  4, 67,  7, 31, 13, 12, 27, 11,  3,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n","         1,  1,  1,  1]), 'labels': tensor([   2,    8,    5,   16,   19,    6,   10,    5,    7,    4,   17,    4,\n","         516,    6,    9,    5,    7,    4,   17,    4, 1172,    3,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1])}\n","Campione 4: {'input_ids': tensor([  2,   5,  28,   9, 135,   8,   4,  54,   7,  17,  11,   3,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1]), 'labels': tensor([   2,    8,    5,   24,    6,   10,    5,    7,    4,   11,    4, 1060,\n","           6,    9,    5,    7,    4,   11,    4,  458,    3,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n","           1,    1,    1,    1])}\n","Campione 5: {'input_ids': tensor([  2,   5,  14,  19,   9, 179,   8,   4,  46,   7,  33,  13,  12,  17,\n","         11,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1]), 'labels': tensor([  2,   8,   5,  14,  18,   6,  10,   5,   7,   4,  11,   4, 417,   6,\n","          9,   5,   7,   4,  11,   4, 419,   3,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n","          1,   1,   1,   1])}\n"]}],"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, file_path: str):\n","        self.file_path = file_path\n","        self.data = pd.read_csv(file_path)\n","        self.inputs = self.data[\"Input\"].to_list()\n","        self.outputs = self.data.apply(lambda row: f'asset: {row[\"Asset\"]}, start: {row[\"Start\"]}, end: {row[\"End\"]}', axis=1).tolist()\n","\n","        self.tokenizer = get_tokenizer(tokenizer=\"spacy\", language=\"it_core_news_sm\")\n","        self.vocab_specials = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n","        self.source_vocab = self.__build_vocab__(self.inputs)\n","        self.target_vocab = self.__build_vocab__(self.outputs)\n","\n","        self.source_vocab.set_default_index(self.source_vocab[\"<unk>\"])\n","        self.target_vocab.set_default_index(self.target_vocab[\"<unk>\"])\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        # 1. Recupero input e relativo output atteso\n","        source = self.inputs[index]\n","        target = self.outputs[index]\n","\n","        # 2. Trasformazione del testo di input\n","        transformed_input = self.__transform__(source, self.source_vocab)\n","\n","        # 3. Trasformazione dell'output\n","        transformed_output = self.__transform__(target, self.target_vocab)\n","\n","        return {\n","            \"input_ids\": transformed_input,\n","            \"labels\": transformed_output\n","        }\n","\n","    def __yield_tokens__(self, sentences):\n","        for text in sentences:\n","            yield self.tokenizer(text)\n","\n","    def __build_vocab__(self, sentences):\n","        return build_vocab_from_iterator(\n","            iterator=self.__yield_tokens__(sentences),\n","            specials=self.vocab_specials,\n","            special_first=True\n","        )\n","\n","    def __transform__(self, sentence, vocab) -> Tensor:\n","        tokens = self.tokenizer(sentence)\n","        transform_pipeline = T.Sequential(\n","            # Converte le parole nei rispettivi indici del vocabolario\n","            T.VocabTransform(vocab),\n","\n","            # Aggiunge <sos> all'inizio della frase.\n","            # 2 è l'indice che ha il token nel vocabolario (vedi vocab_specials)\n","            T.AddToken(token=2, begin=True),\n","\n","            T.Truncate(max_seq_len=256),\n","\n","            # Aggiunge <eos> alla fine della frase.\n","            # 3 è l'indice che ha il token nel vocabolario (vedi vocab_specials)\n","            T.AddToken(3, begin=False),\n","\n","            # Trasforma in un tensore\n","            T.ToTensor(padding_value=1),\n","\n","            T.PadTransform(max_length=256, pad_value=1))\n","        return transform_pipeline(tokens)\n","\n","    def info(self):\n","        print(\"---------------------------------\")\n","        print(\"Dataset Info\")\n","        print(\"---------------------------------\")\n","        print(f\"Data location:\\t\\\"{self.file_path}\\\"\")\n","        print(f\"Data length:\\t{len(self.data)} records\")\n","        print(f\"Source vocab length:\\t{len(self.source_vocab)} words\")\n","        print(f\"Target vocab length:\\t{len(self.target_vocab)} words\")\n","        print(\"---------------------------------\")\n","        print(\"END Info\")\n","        print(\"---------------------------------\")\n","\n","if __name__ == \"__main__\":\n","    cd = CustomDataset(file_path=\"datasets/train/train.csv\")\n","    cd.info()\n","\n","    for i, cd in enumerate(cd):\n","        if i > 5: break\n","        print(f\"Campione {i}: {cd}\")\n"]},{"cell_type":"markdown","metadata":{"id":"8qj4PXdPMVRd"},"source":["# 4. Model"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"grluxAwyLKBC","executionInfo":{"status":"ok","timestamp":1737736026846,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n","        super(Encoder, self).__init__()\n","\n","        self.dropout = nn.Dropout(p)\n","        self.embedding = nn.Embedding(input_size, embedding_size)\n","        self.rnn = nn.LSTM(\n","            embedding_size, hidden_size, num_layers, dropout=p, batch_first=True\n","        )\n","\n","    def forward(self, x):\n","        embedded = self.dropout(self.embedding(x))\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        return hidden, cell\n"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"XGoBf547L6Xv","executionInfo":{"status":"ok","timestamp":1737736026846,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, output_size, embedding_size, hidden_size, num_layers, p):\n","        super(Decoder, self).__init__()\n","\n","        self.dropout = nn.Dropout(p)\n","        self.embedding = nn.Embedding(output_size, embedding_size)\n","        self.rnn = nn.LSTM(embedding_size, hidden_size, num_layers, dropout=p)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x, hidden, cell):\n","        x = x.unsqueeze(0)\n","        embedded = self.dropout(self.embedding(x))\n","        outputs, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n","        predictions = self.fc(outputs)\n","\n","        predictions = predictions.squeeze(0)\n","        return predictions, hidden, cell\n"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"0OsXUb5qMMkp","executionInfo":{"status":"ok","timestamp":1737736026846,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["class SpaceAIModel(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super(SpaceAIModel, self).__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, source, target, teacher_forcing_ratio=0.5):\n","        target_len = target.shape[1]\n","        batch_size = target.shape[0]\n","        target_vocab_size = self.decoder.fc.out_features\n","\n","        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(self.device)\n","        hidden, cell = self.encoder(source)\n","        input = target[:, 0]\n","\n","        for t in range(1, target_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell)\n","            outputs[t] = output\n","            best_guess = output.argmax(1)\n","            input = (\n","                target[:, t]\n","                if torch.rand(1).item() < teacher_forcing_ratio\n","                else best_guess\n","            )\n","\n","        return outputs\n"]},{"cell_type":"markdown","source":["# 5. Metrics"],"metadata":{"id":"RqWQdDJ_wqQy"}},{"cell_type":"code","source":["class Metrics:\n","    def __init__(self, real: np.array, prediction: np.array):\n","        self.real = real\n","        self.prediction = prediction\n","\n","    def token_level_accuracy(self):\n","        correct = 0\n","        total = 0\n","        for pred, real in zip(self.prediction, self.real):\n","            correct += sum(\n","                pred_token == real_token for pred_token, real_token in zip(pred, real)\n","            )\n","            total += len(real)\n","\n","        return correct / total\n"],"metadata":{"id":"pvH6qbVUwuGN","executionInfo":{"status":"ok","timestamp":1737736026846,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pArMzHsDMio2"},"source":["# 6. Runner"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"N-1qEbGbMiCJ","executionInfo":{"status":"ok","timestamp":1737736026847,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[],"source":["class SpaceAIRunner:\n","    def __init__(\n","        self,\n","        batch_size,\n","        epochs,\n","        source_vocab,\n","        target_vocab,\n","        embedding_size,\n","        hidden_size,\n","        num_layers,\n","        dropout,\n","        lr,\n","    ):\n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","\n","        self.source_vocab = source_vocab\n","        self.target_vocab = target_vocab\n","\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        encoder = Encoder(\n","            len(source_vocab), embedding_size, hidden_size, num_layers, dropout\n","        ).to(self.device)\n","        decoder = Decoder(\n","            len(target_vocab), embedding_size, hidden_size, num_layers, dropout\n","        ).to(self.device)\n","\n","        self.net = SpaceAIModel(encoder, decoder, self.device).to(self.device)\n","\n","        self.loss = torch.nn.CrossEntropyLoss()\n","        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n","\n","    def train(\n","        self,\n","        train_loader: torch.utils.data.DataLoader,\n","        validation_loader: torch.utils.data.DataLoader,\n","        out_root: str,\n","    ):\n","        out_root = Path(out_root)\n","        if not out_root.exists():\n","            out_root.mkdir()\n","\n","        step_counter = 0\n","        step_monitor = 5\n","        ep_monitor = 2\n","        losses_x, losses_y = [], []\n","        run_losses_x, run_losses_y = [], []\n","\n","        for epoch in range(self.epochs):\n","            self.net.train()\n","\n","            running_loss = 0.0\n","\n","            print(f\"Epoch {epoch + 1} / {self.epochs}\")\n","            for i, data in enumerate(train_loader):\n","                source, target = data[\"input_ids\"].to(self.device), data[\"labels\"].to(\n","                    self.device\n","                )\n","                outputs = self.net(source, target)\n","\n","                outputs = outputs[1:].reshape(-1, outputs.shape[2])\n","                target = target.T[1:].reshape(-1)\n","\n","                loss = self.loss(outputs, target)\n","                self.optimizer.zero_grad()\n","                loss.backward()\n","                self.optimizer.step()\n","\n","                running_loss += loss.item()\n","                if (i + 1) % step_monitor == 0:\n","                    run_losses_y.append(running_loss / step_monitor)\n","                    run_losses_x.append(step_counter)\n","                    print(\n","                        f\"GlobalStep: {(step_counter + 1):5d} - [Epoca: {epoch + 1:3d}, Step: {i + 1:5d}] loss: {loss.item():.6f} - running_loss: {(running_loss / step_monitor):.6f}\"\n","                    )\n","                    running_loss = 0.0\n","\n","                losses_x.append(step_counter)\n","                losses_y.append(loss.item())\n","                step_counter += 1\n","\n","            if (epoch + 1) % ep_monitor == 0:\n","                print(f\"\\n *** *** VALIDATION *** ***\")\n","                t_accuracy = self.test(validation_loader, use_current_net=True)\n","                print(\n","                    f\"GlobalStep: {step_counter:5d} - [Epoca: {epoch + 1:3d}, token_level_accuracy: {t_accuracy:.2f}\"\n","                )\n","\n","        print(\"Finished training!\")\n","\n","        torch.save(self.net.state_dict(), out_root / \"model_sd.pth\")\n","        torch.save(self.net, out_root / \"model.pth\")\n","        print(\"Model saved!\")\n","\n","        plt.plot(losses_x, losses_y)\n","        plt.plot(run_losses_x, run_losses_y)\n","        plt.show()\n","\n","    def test(self, test_loader: torch.utils.data.DataLoader, use_current_net=False):\n","        net = self.net\n","        if use_current_net == False:\n","            try:\n","                net.load_state_dict(torch.load(\"out/model_sd.pth\"))\n","            except:\n","                print(\"Model not found.\")\n","                return\n","\n","        net.eval()\n","\n","        total_target = []\n","        total_prediction = []\n","\n","        with torch.no_grad():\n","            for i, data in enumerate(test_loader):\n","                source, target = data[\"input_ids\"].to(self.device), data[\"labels\"].to(\n","                    self.device\n","                )\n","                outputs = net(source, target, teacher_forcing_ratio=0)\n","                output_tokens = outputs.argmax(2).T\n","\n","                for i in range(len(source)):\n","                    input_sentence = \" \".join(\n","                        self.source_vocab.lookup_tokens(source[i].tolist())\n","                    )\n","                    target_json = self.target_vocab.lookup_tokens(target[i].tolist())\n","                    predicted_json = self.target_vocab.lookup_tokens(\n","                        output_tokens[i].tolist()\n","                    )\n","\n","                    total_target.append(target_json)\n","                    total_prediction.append(predicted_json)\n","\n","        metrics = Metrics(total_target, total_prediction)\n","        token_level_accuracy = metrics.token_level_accuracy()\n","        return token_level_accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"hI1runHeSEHq"},"source":["# 7. Main"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eUUo38sUSMEw","outputId":"2cdc688b-1152-41db-8828-f405084f091a","executionInfo":{"status":"ok","timestamp":1737736125707,"user_tz":-60,"elapsed":98865,"user":{"displayName":"Alessandro Di Roma","userId":"14787101213019934812"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n","  warnings.warn(Warnings.W111)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 / 5\n","GlobalStep:     5 - [Epoca:   1, Step:     5] loss: 3.497605 - running_loss: 5.687072\n","GlobalStep:    10 - [Epoca:   1, Step:    10] loss: 0.632149 - running_loss: 1.121101\n","GlobalStep:    15 - [Epoca:   1, Step:    15] loss: 0.444084 - running_loss: 0.555837\n","GlobalStep:    20 - [Epoca:   1, Step:    20] loss: 0.361927 - running_loss: 0.383238\n","GlobalStep:    25 - [Epoca:   1, Step:    25] loss: 0.311705 - running_loss: 0.329694\n","GlobalStep:    30 - [Epoca:   1, Step:    30] loss: 0.294427 - running_loss: 0.299561\n","GlobalStep:    35 - [Epoca:   1, Step:    35] loss: 0.273248 - running_loss: 0.281179\n","GlobalStep:    40 - [Epoca:   1, Step:    40] loss: 0.265604 - running_loss: 0.269052\n","GlobalStep:    45 - [Epoca:   1, Step:    45] loss: 0.258284 - running_loss: 0.260074\n","GlobalStep:    50 - [Epoca:   1, Step:    50] loss: 0.252560 - running_loss: 0.254086\n","Epoch 2 / 5\n","GlobalStep:    55 - [Epoca:   2, Step:     5] loss: 0.244221 - running_loss: 0.247241\n","GlobalStep:    60 - [Epoca:   2, Step:    10] loss: 0.240841 - running_loss: 0.243508\n","GlobalStep:    65 - [Epoca:   2, Step:    15] loss: 0.237717 - running_loss: 0.237796\n","GlobalStep:    70 - [Epoca:   2, Step:    20] loss: 0.233244 - running_loss: 0.234335\n","GlobalStep:    75 - [Epoca:   2, Step:    25] loss: 0.230545 - running_loss: 0.231324\n","GlobalStep:    80 - [Epoca:   2, Step:    30] loss: 0.227915 - running_loss: 0.227965\n","GlobalStep:    85 - [Epoca:   2, Step:    35] loss: 0.224642 - running_loss: 0.225052\n","GlobalStep:    90 - [Epoca:   2, Step:    40] loss: 0.223006 - running_loss: 0.223511\n","GlobalStep:    95 - [Epoca:   2, Step:    45] loss: 0.217152 - running_loss: 0.220241\n","GlobalStep:   100 - [Epoca:   2, Step:    50] loss: 0.218683 - running_loss: 0.219352\n","\n"," *** *** VALIDATION *** ***\n","GlobalStep:   101 - [Epoca:   2, token_level_accuracy: 0.94\n","Epoch 3 / 5\n","GlobalStep:   105 - [Epoca:   3, Step:     5] loss: 0.213938 - running_loss: 0.215813\n","GlobalStep:   110 - [Epoca:   3, Step:    10] loss: 0.212368 - running_loss: 0.214983\n","GlobalStep:   115 - [Epoca:   3, Step:    15] loss: 0.212433 - running_loss: 0.211970\n","GlobalStep:   120 - [Epoca:   3, Step:    20] loss: 0.208080 - running_loss: 0.209209\n","GlobalStep:   125 - [Epoca:   3, Step:    25] loss: 0.208989 - running_loss: 0.208511\n","GlobalStep:   130 - [Epoca:   3, Step:    30] loss: 0.207149 - running_loss: 0.207478\n","GlobalStep:   135 - [Epoca:   3, Step:    35] loss: 0.204422 - running_loss: 0.204658\n","GlobalStep:   140 - [Epoca:   3, Step:    40] loss: 0.204096 - running_loss: 0.204222\n","GlobalStep:   145 - [Epoca:   3, Step:    45] loss: 0.199378 - running_loss: 0.201875\n","GlobalStep:   150 - [Epoca:   3, Step:    50] loss: 0.202726 - running_loss: 0.202305\n","Epoch 4 / 5\n","GlobalStep:   155 - [Epoca:   4, Step:     5] loss: 0.198444 - running_loss: 0.200600\n","GlobalStep:   160 - [Epoca:   4, Step:    10] loss: 0.196445 - running_loss: 0.199481\n","GlobalStep:   165 - [Epoca:   4, Step:    15] loss: 0.199023 - running_loss: 0.197345\n","GlobalStep:   170 - [Epoca:   4, Step:    20] loss: 0.193871 - running_loss: 0.196445\n","GlobalStep:   175 - [Epoca:   4, Step:    25] loss: 0.198187 - running_loss: 0.194942\n","GlobalStep:   180 - [Epoca:   4, Step:    30] loss: 0.195870 - running_loss: 0.194771\n","GlobalStep:   185 - [Epoca:   4, Step:    35] loss: 0.192571 - running_loss: 0.193351\n","GlobalStep:   190 - [Epoca:   4, Step:    40] loss: 0.191377 - running_loss: 0.192889\n","GlobalStep:   195 - [Epoca:   4, Step:    45] loss: 0.188520 - running_loss: 0.191407\n","GlobalStep:   200 - [Epoca:   4, Step:    50] loss: 0.192437 - running_loss: 0.193759\n","\n"," *** *** VALIDATION *** ***\n","GlobalStep:   201 - [Epoca:   4, token_level_accuracy: 0.96\n","Epoch 5 / 5\n","GlobalStep:   205 - [Epoca:   5, Step:     5] loss: 0.189361 - running_loss: 0.190491\n","GlobalStep:   210 - [Epoca:   5, Step:    10] loss: 0.188634 - running_loss: 0.191441\n","GlobalStep:   215 - [Epoca:   5, Step:    15] loss: 0.185831 - running_loss: 0.187076\n","GlobalStep:   220 - [Epoca:   5, Step:    20] loss: 0.182909 - running_loss: 0.183531\n","GlobalStep:   225 - [Epoca:   5, Step:    25] loss: 0.183116 - running_loss: 0.183202\n","GlobalStep:   230 - [Epoca:   5, Step:    30] loss: 0.180234 - running_loss: 0.179449\n","GlobalStep:   235 - [Epoca:   5, Step:    35] loss: 0.175586 - running_loss: 0.176164\n","GlobalStep:   240 - [Epoca:   5, Step:    40] loss: 0.176262 - running_loss: 0.175588\n","GlobalStep:   245 - [Epoca:   5, Step:    45] loss: 0.169940 - running_loss: 0.173914\n","GlobalStep:   250 - [Epoca:   5, Step:    50] loss: 0.173348 - running_loss: 0.174125\n","Finished training!\n","Model saved!\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["BATCH_SIZE = 20\n","EPOCHS = 5\n","SHUFFLE = False\n","EMB_DIM = 150\n","HID_DIM = 300\n","N_LAYERS = 2\n","DROPOUT = 0.5\n","TRAIN = True\n","LR = 0.001\n","\n","\n","tr_dataset = CustomDataset(file_path=\"datasets/train/train.csv\")\n","te_dataset = CustomDataset(file_path=\"datasets/test/test.csv\")\n","va_dataset = CustomDataset(file_path=\"datasets/validation/validation.csv\")\n","\n","tr_loader = torch.utils.data.DataLoader(\n","    tr_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",")\n","te_loader = torch.utils.data.DataLoader(\n","    te_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",")\n","va_loader = torch.utils.data.DataLoader(\n","    va_dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE\n",")\n","\n","runner = SpaceAIRunner(\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    source_vocab=tr_dataset.source_vocab,\n","    target_vocab=tr_dataset.target_vocab,\n","    embedding_size=EMB_DIM,\n","    hidden_size=HID_DIM,\n","    num_layers=N_LAYERS,\n","    dropout=DROPOUT,\n","    lr=LR,\n",")\n","\n","if TRAIN:\n","    runner.train(train_loader=tr_loader, validation_loader=va_loader, out_root=\"out\")\n","else:\n","    print(f\"\\n *** *** TESTING *** ***\")\n","    t_accuracy, s_accuracy = runner.test(test_loader=te_loader)\n","    print(\"Finished testing!\")\n","    print(f\"token_level_accuracy: {t_accuracy:.2f}\")\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1QZP_NZ-IhIkHJolGE4DJFS5z72jRWyLK","authorship_tag":"ABX9TyPOCz1PvcGCclyjeSRWZpdi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}